{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQHRQ94tgMuccgUmMAFCkf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WhiteDevil7368/pdftextextxtract/blob/main/pdf_to_text_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4i26H1Iokim3",
        "outputId": "ba023af8-9f51-4680-9fd3-0f046f20e427"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf2\n",
            "Successfully installed pypdf2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xzLsosTqkZsI"
      },
      "outputs": [],
      "source": [
        "import PyPDF2\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(pdf_file):\n",
        "    with open(pdf_file, 'rb') as f:\n",
        "        pdf = PyPDF2.PdfReader(f)\n",
        "        text = ''\n",
        "        for page in pdf.pages:\n",
        "            text += page.extract_text()\n",
        "    return text"
      ],
      "metadata": {
        "id": "Rxrqy1c6krUd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    nltk.download('punkt')\n",
        "    nltk.download('stopwords')\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
        "    preprocessed_text = ' '.join(filtered_tokens)\n",
        "    return preprocessed_text  # Return a single string"
      ],
      "metadata": {
        "id": "ckVDl7QEku7Y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_ml_model(text_data):\n",
        "    vectorizer = CountVectorizer()\n",
        "    X = vectorizer.fit_transform(text_data)\n",
        "    y = [0] * len(text_data)  # assume all samples belong to one class\n",
        "    model = MultinomialNB()\n",
        "    model.fit(X, y)\n",
        "    return model"
      ],
      "metadata": {
        "id": "IpxocTf7kxnQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_file = 'resume amazon.pdf'\n",
        "text = extract_text_from_pdf(pdf_file)\n",
        "preprocessed_text = preprocess_text(text)\n",
        "model = create_ml_model([preprocessed_text])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n09wg1mDk0FT",
        "outputId": "1c400734-ed7c-4347-bd28-9446e5a29ec7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Extracted Text:\")\n",
        "print(text)\n",
        "print(\"\\nPreprocessed Text:\")\n",
        "print(preprocessed_text)\n",
        "print(\"\\nTrained Model:\")\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ia0O5volmt7",
        "outputId": "ceb7d6a5-0036-409b-982b-39f9c4f61200"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Text:\n",
            "Kushagra Gangwar\n",
            "Software Developer\n",
            "(+91) 99973 30289\n",
            "kushagragangwar4@gmail.com\n",
            "Github\n",
            "Linkedin\n",
            "EXPERIENCE\n",
            "Springworks,\n",
            "Remote —\n",
            "Software Engineer Intern\n",
            "June 2021 - PRESENT\n",
            "I\n",
            "currently\n",
            "work\n",
            "as\n",
            "a\n",
            "full-stack\n",
            "developer\n",
            "which\n",
            "involves \n",
            "planning\n",
            "and\n",
            "incorporating\n",
            "new\n",
            "features\n",
            "in\n",
            "the\n",
            "projects\n",
            "from \n",
            "their stage of development to deployment. \n",
            "Currently,\n",
            "I\n",
            "am\n",
            "working\n",
            "on\n",
            "a\n",
            "project\n",
            "called\n",
            "Nachamu\n",
            ",\n",
            "in \n",
            "which,\n",
            "till\n",
            "now,\n",
            "I’ve\n",
            "created\n",
            "new\n",
            "APIs,\n",
            "updated\n",
            "some\n",
            "APIs, \n",
            "reduced\n",
            "LOC,\n",
            "which\n",
            "highly\n",
            "a\u0000ected\n",
            "e\u0000ciency.\n",
            "Also\n",
            "worked\n",
            "on \n",
            "frontend to integrate APIs using React.JS\n",
            "EDUCATION\n",
            "GLA University,\n",
            "Mathura —\n",
            "B.Tech. CSE\n",
            "August 2018 - June 2022\n",
            "CGPA - 8.05\n",
            "Ben-Hur Public School,\n",
            "Pilibhit —\n",
            "Senior Secondary\n",
            "PCM\n",
            "| 2018\n",
            "PROJECTS\n",
            "Things.Do\n",
            "—\n",
            "Web Development\n",
            "HTML, CSS, JavaScript, Bootstrap, MongoDB, NodeJS, Express\n",
            "E Diary\n",
            "—\n",
            "Web Development\n",
            "ReactJS, NodeJS, MongoDB.\n",
            "PDF Text Analysis\n",
            "—\n",
            "Data Science\n",
            "Python\n",
            "Neumo_calci\n",
            "—\n",
            "Web Development\n",
            "HTML, CSS, Javascript\n",
            "SKILLS\n",
            "•\n",
            "Java\n",
            "•\n",
            "JavaScript\n",
            "•\n",
            "Node.JS\n",
            "•\n",
            "React.JS\n",
            "•\n",
            "Express.JS\n",
            "•\n",
            "Git\n",
            "•\n",
            "MongoDB\n",
            "•\n",
            "Python\n",
            "•\n",
            "SQL\n",
            "•\n",
            "HTML5\n",
            "•\n",
            "CSS3\n",
            "•\n",
            "TypeScript\n",
            "ACHIEVEMENTS\n",
            "●\n",
            "Research paper\n",
            "on\n",
            "PDF\n",
            "Text Analysis and\n",
            "Sentiment Analysis\n",
            "got\n",
            "selected in\n",
            "INTERNATIONAL\n",
            "CONFERENCE ON\n",
            "INNOVATIVE\n",
            "COMPUTING AND\n",
            "COMMUNICATION\n",
            "(ICICC-2021).\n",
            "ADDITIONAL INFO\n",
            "●\n",
            "Solved\n",
            "400+\n",
            "questions on\n",
            "Leetcode.\n",
            "●\n",
            "Proﬁcient\n",
            "in\n",
            "Data\n",
            "Structures and\n",
            "Algorithms.\n",
            "\n",
            "Preprocessed Text:\n",
            "Kushagra Gangwar Software Developer ( +91 ) 99973 30289 kushagragangwar4 @ gmail.com Github Linkedin EXPERIENCE Springworks , Remote — Software Engineer Intern June 2021 - PRESENT I currently work full-stack developer involves planning incorporating new features projects stage development deployment . Currently , I working project called Nachamu , , till , I ’ created new APIs , updated APIs , reduced LOC , highly a\u0000ected e\u0000ciency . Also worked frontend integrate APIs using React.JS EDUCATION GLA University , Mathura — B.Tech . CSE August 2018 - June 2022 CGPA - 8.05 Ben-Hur Public School , Pilibhit — Senior Secondary PCM | 2018 PROJECTS Things.Do — Web Development HTML , CSS , JavaScript , Bootstrap , MongoDB , NodeJS , Express E Diary — Web Development ReactJS , NodeJS , MongoDB . PDF Text Analysis — Data Science Python Neumo_calci — Web Development HTML , CSS , Javascript SKILLS • Java • JavaScript • Node.JS • React.JS • Express.JS • Git • MongoDB • Python • SQL • HTML5 • CSS3 • TypeScript ACHIEVEMENTS ● Research paper PDF Text Analysis Sentiment Analysis got selected INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING AND COMMUNICATION ( ICICC-2021 ) . ADDITIONAL INFO ● Solved 400+ questions Leetcode . ● Proﬁcient Data Structures Algorithms .\n",
            "\n",
            "Trained Model:\n",
            "MultinomialNB()\n"
          ]
        }
      ]
    }
  ]
}